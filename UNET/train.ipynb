{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "THIS FILE IS DEPRECIATED.  \n",
    "FILE IS FUNCTIONAL; HOWEVER, TRAINS POORLY.  \n",
    "USE THE `sm_train` FILES FOR BETTER RESULTS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "# filters out info logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "from data_loader import *\n",
    "from unet_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prints data info when True\n",
    "prints = False\n",
    "\n",
    "## Model Params\n",
    "batch_size = 25\n",
    "epochs = 100\n",
    "\n",
    "## Model Checkpoint paths\n",
    "best_path = f'.\\\\..\\\\results\\\\{epochs}_best_short_soft_checkpoint'\n",
    "recent_path = f'.\\\\..\\\\results\\\\{epochs}_recent_short_soft_checkpoint'\n",
    "\n",
    "## training and masks dir\n",
    "input_dir = \".\\\\..\\\\data\\\\datasets\\\\smaller_birds_dataset\\\\raw\\\\\"\n",
    "mask_dir = \".\\\\..\\\\data\\\\datasets\\\\smaller_birds_dataset\\\\masks\\\\\"\n",
    "\n",
    "## Image size\n",
    "# img_size = (1024, 1024)\n",
    "# img_size = (512, 512)\n",
    "img_size = (256, 256)\n",
    "# img_size = (128, 128)\n",
    "# img_size = (64, 64)\n",
    "\n",
    "## Validation Percentage\n",
    "validation_percent = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets number of classes\n",
    "bird_categories = sorted(os.listdir(input_dir))\n",
    "bird_categories = [s for s in bird_categories if s != '.gitkeep']\n",
    "num_classes = len(bird_categories)\n",
    "if prints:\n",
    "    print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Data lists. Images and Masks\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(root, file) \n",
    "        for root, _, files in os.walk(input_dir) \n",
    "        for file in files \n",
    "        if file.lower().endswith('.jpg') and not file.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(root, file) \n",
    "        for root, _, files in os.walk(mask_dir) \n",
    "        for file in files \n",
    "        if file.lower().endswith('.png') and not file.startswith(\".\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find masks and images that aren't found in eachother's directories\n",
    "mismatched_paths =[]\n",
    "for im in input_img_paths:\n",
    "    im_mask = im.replace(mask_dir, input_dir).replace('png','jpg')\n",
    "    if not os.path.exists(im_mask):\n",
    "        mismatched_paths.append(im)\n",
    "for im_mask in target_img_paths:\n",
    "    im = im.replace(input_dir, mask_dir).replace('jpg','png')\n",
    "    if not os.path.exists(im):\n",
    "        mismatched_paths.append(im_mask)\n",
    "if mismatched_paths is not []:\n",
    "    print(\"Images do not match with masks:\\n\", mismatched_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Makes sures there are the same number of images as masks\n",
    "if len(input_img_paths) != len(target_img_paths):\n",
    "    raise Exception(f\"ERROR: LABELS AND INPUTS HAVE DIFFERENT SIZES.\\n\\tInputs: {len(input_img_paths)}\\n\\tInputs: {len(target_img_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints all input respective masks\n",
    "if prints:\n",
    "    print(\"Number of samples:\", len(input_img_paths))\n",
    "    for input_path, target_path in zip(input_img_paths[:5], target_img_paths[:5]):\n",
    "        print(input_path, \"|\", target_path)\n",
    "    for input_path, target_path in zip(input_img_paths[-5:], target_img_paths[-5:]):\n",
    "        print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session() # clears previous sessions\n",
    "\n",
    "# Build model\n",
    "model = SOFTMAX_UNET(img_size, num_classes) \n",
    "# RESIDUAL_UNET\n",
    "# GPT_UNET\n",
    "# SOFTMAX_UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our img paths into a training and a validation set\n",
    "val_samples = int(len(input_img_paths) * validation_percent)\n",
    "rand_seed = random.randint(0,2000000)\n",
    "random.Random(rand_seed).shuffle(input_img_paths)\n",
    "random.Random(rand_seed).shuffle(target_img_paths)\n",
    "\n",
    "train_input_img_paths = input_img_paths[:-val_samples]\n",
    "train_target_img_paths = target_img_paths[:-val_samples]\n",
    "val_input_img_paths = input_img_paths[-val_samples:]\n",
    "val_target_img_paths = target_img_paths[-val_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prints im ands correlated validation ims\n",
    "if prints:\n",
    "    for input_path, target_path in zip(val_input_img_paths[:5], val_target_img_paths[:5]):\n",
    "        print(input_path, \"|\", target_path)\n",
    "    for input_path, target_path in zip(input_img_paths[-5:], target_img_paths[-5:]):\n",
    "        print(input_path, \"|\", target_path)\n",
    "        \n",
    "## Raises Exception is a file in the training dataset is found in the validation\n",
    "for im in train_input_img_paths:\n",
    "    for val in val_input_img_paths:\n",
    "        if im==val:\n",
    "            raise Exception(\"ERROR: FILE IN BOTH TRAINING AND VALIDATION: \", im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Augmentations and Generators\n",
    "train_data_gen_args = dict(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_data_gen = ImageDataGenerator(**train_data_gen_args)\n",
    "val_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation\n",
    "train_gen = Dataloader(batch_size, img_size, train_input_img_paths, train_target_img_paths, num_classes,train_data_gen)\n",
    "val_gen = Dataloader(batch_size, img_size, val_input_img_paths, val_target_img_paths, num_classes,val_data_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Params\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(best_path, monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.ModelCheckpoint(recent_path)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model.fit(train_gen, epochs=epochs, validation_data=val_gen, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path = './../results/50_best_soft'\n",
    "recent_path = './../results/50_recent_soft'\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(best_path, monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.ModelCheckpoint(recent_path)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, epochs=50, validation_data=val_gen, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
