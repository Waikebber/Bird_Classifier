{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input info\n",
    "best_checkpoint = '.\\\\results\\\\best_model.h5'\n",
    "recent_checkpoint = '.\\\\results\\\\recent_model.h5'\n",
    "\n",
    "data_dir = '.\\\\data'\n",
    "train_dir = os.path.join(data_dir,'training')\n",
    "val_dir = os.path.join(data_dir,'validation')\n",
    "bird_categories = sorted(os.listdir(train_dir))\n",
    "num_classes = len(bird_categories)\n",
    "\n",
    "img_size = (128, 128)\n",
    "batch_size = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    \"\"\" Given a Directory, creates two lists. \n",
    "        One is a list of all the images.\n",
    "        The other is a list of the names corresponding to the other list.\n",
    "\n",
    "    Args:\n",
    "        directory (str): Directory path to the data (training or validation)\n",
    "\n",
    "    Returns:\n",
    "        lst: List of all image arrays\n",
    "        lst: List of all image labels\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for category_id, category in enumerate(bird_categories):\n",
    "        category_dir = os.path.join(directory, category)\n",
    "        for image_name in os.listdir(category_dir):\n",
    "            image_path = os.path.join(category_dir, image_name)\n",
    "            image = keras.preprocessing.image.load_img(image_path, target_size=img_size)\n",
    "            image_array = keras.preprocessing.image.img_to_array(image)\n",
    "            images.append(image_array)\n",
    "            labels.append(category_id)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = load_data(train_dir)\n",
    "val_images, val_labels = load_data(val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNET():\n",
    "    \"\"\" UNET model with subpixel convelution\n",
    "    \"\"\"\n",
    "    inputs = keras.Input(shape=(img_size[0], img_size[1], 3))\n",
    "    \n",
    "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    # Add subpixel convolution layer\n",
    "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = keras.layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    up1 = keras.layers.UpSampling2D(size=(2, 2))(conv2)\n",
    "    up1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(up1)\n",
    "    up1 = keras.layers.Conv2D(64, 3, activation='relu', padding='same')(up1)\n",
    "    up1 = keras.layers.Conv2D(32, 3, activation='relu', padding='same')(up1)\n",
    "    up1 = keras.layers.Conv2D(32, 3, activation='relu', padding='same')(up1)\n",
    "    conv3 = keras.layers.Conv2D(num_classes, 3, activation='softmax', padding='same')(up1)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=conv3)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNET()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Generators\n",
    "# Training data augmentations\n",
    "train_data_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0,\n",
    "                                                              rotation_range=20,\n",
    "                                                              width_shift_range=0.1,\n",
    "                                                              height_shift_range=0.1,\n",
    "                                                              shear_range=0.1,\n",
    "                                                              zoom_range=0.1,\n",
    "                                                              horizontal_flip=True,\n",
    "                                                              vertical_flip=True)\n",
    "val_data_gen = keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_data_gen.flow(train_images, train_labels, batch_size=batch_size)\n",
    "val_generator = val_data_gen.flow(val_images, val_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "# Saves the most recent and best checkpoints\n",
    "checkpoint_best = keras.callbacks.ModelCheckpoint(best_checkpoint, monitor='val_loss', save_best_only=True)\n",
    "checkpoint_recent = keras.callbacks.ModelCheckpoint(recent_checkpoint)\n",
    "\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=len(train_images) // batch_size,\n",
    "                              epochs=epochs, validation_data=val_generator,\n",
    "                              validation_steps=len(val_images) // batch_size,\n",
    "                              callbacks=[checkpoint_best, checkpoint_recent])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
