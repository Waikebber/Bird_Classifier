{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verify_masks\n",
    "This script verifies that all images in a dataset directory have a corresponding mask.  Images that do not have a mask are uploaded to LabelBox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from labelbox_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LabelBox Params\n",
    "api_key = ''\n",
    "proj_name = 'Birds_Retry'\n",
    "ontology_name = 'Birds_Retry'\n",
    "\n",
    "# TXT file to be made with project and ontology IDs within it\n",
    "proj_id_txt = \".\\\\..\\\\data\\\\projects\\\\\"+project_name+\".txt\"\n",
    "\n",
    "## Dataset Directory\n",
    "dataset_dir = '.\\\\..\\\\data\\\\datasets\\\\birds_dataset\\\\'\n",
    "masks_dir = os.path.join(dataset_dir, 'masks')\n",
    "images_dir = os.path.join(dataset_dir, 'raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_mask_ims = []\n",
    "for classes in os.listdir(images_dir):\n",
    "    if classes != '.gitkeep':\n",
    "        masks = [x.replace('.png', '.jpg') for x in os.listdir(os.path.join(masks_dir, classes))]\n",
    "        for im in os.listdir(os.path.join(images_dir, classes)):\n",
    "            if im not in masks:\n",
    "                no_mask_ims.append(os.path.join(images_dir, classes, im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelBox(api_key=api_key, img_lst=no_mask_ims, project_name=proj_name, ontology_name=ontology_name, proj_id=None, directory_path=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all images that could not be uploaded to LabelBox\n",
    "rm_lst = []\n",
    "for error in tqdm(labels.find_error_sets()):\n",
    "    data_lst = [ os.path.join(raw_dir, error.replace(\"-s \", \"'s \"),x) for x in os.listdir(os.path.join(raw_dir, error.replace(\"-s \", \"'s \")))]\n",
    "    rm_lst.append(labels.labelbox_dataset_lst(error.replace(\"-s \", \"'s \"), data_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes images that could not be uploaded from the dataset \n",
    "for im_lst in rm_lst:\n",
    "    for im in im_lst:\n",
    "        print(im)\n",
    "        os.remove(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates TXT file with project and ontolgy IDs\n",
    "if os.path.exists(proj_id_txt):\n",
    "    valid_path = False\n",
    "    count = 0\n",
    "    while not valid_path:\n",
    "        new_name =  proj_id_txt.split(\".txt\")[0] + str(count) + \".txt\"\n",
    "        if not os.path.exists(new_name):\n",
    "            valid_path = True\n",
    "    proj_id_txt = new_name\n",
    "    \n",
    "with open(proj_id_txt, 'w') as f:\n",
    "    f.write(\"Project_name:\"+project_name+\", Project_id:\"+labels.project.uid+\"\\n\"+\n",
    "            \"Ontology_name:\"+ontology_name+\", Ontology_id:\"+labels.ontology)\n",
    "print(\"Project ID: \",labels.project.uid)\n",
    "print(\"Ontology ID: \", labels.ontology)\n",
    "print(\"File made at: \", proj_id_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
